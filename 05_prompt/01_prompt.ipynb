{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai íšŒì‚¬(GPT) ëª¨ë¸ ì‚¬ìš©í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— python setup.py egg_info did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [83 lines of output]\n",
      "      C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— python setup.py egg_info did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [17 lines of output]\n",
      "            Traceback (most recent call last):\n",
      "              File \"<string>\", line 2, in <module>\n",
      "              File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\__init__.py\", line 2, in <module>\n",
      "                from setuptools.extension import Extension, Library\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\extension.py\", line 5, in <module>\n",
      "                from setuptools.dist import _get_unpatched\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\dist.py\", line 7, in <module>\n",
      "                from setuptools.command.install import install\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\command\\__init__.py\", line 8, in <module>\n",
      "                from setuptools.command import install_scripts\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\command\\install_scripts.py\", line 3, in <module>\n",
      "                from pkg_resources import Distribution, PathMetadata, ensure_directory\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\pkg_resources.py\", line 1518, in <module>\n",
      "                register_loader_type(importlib_bootstrap.SourceFileLoader, DefaultProvider)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "            AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: metadata-generation-failed\n",
      "      \n",
      "      Ã— Encountered error while generating package metadata.\n",
      "      â•°â”€> See above for output.\n",
      "      \n",
      "      note: This is an issue with the package mentioned above, not pip.\n",
      "      hint: See above for details.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\installer.py\", line 102, in _fetch_build_egg_no_warn\n",
      "          subprocess.check_call(cmd)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['C:\\\\Users\\\\80416\\\\miniforge3\\\\envs\\\\gpt_env\\\\python.exe', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', 'C:\\\\Users\\\\80416\\\\AppData\\\\Local\\\\Temp\\\\tmpt0h9i25a', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-install-ij0g5nca\\dotenv_f0b4afcc03ef479f92c5bdb9829cd7d2\\setup.py\", line 13, in <module>\n",
      "          setup(name='dotenv',\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py\", line 116, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py\", line 89, in _install_setup_requires\n",
      "          _fetch_build_eggs(dist)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py\", line 94, in _fetch_build_eggs\n",
      "          dist.fetch_build_eggs(dist.setup_requires)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\dist.py\", line 617, in fetch_build_eggs\n",
      "          return _fetch_build_eggs(self, requires)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\installer.py\", line 39, in _fetch_build_eggs\n",
      "          resolved_dists = pkg_resources.working_set.resolve(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 897, in resolve\n",
      "          dist = self._resolve_dist(\n",
      "                 ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 933, in _resolve_dist\n",
      "          dist = best[req.key] = env.best_match(\n",
      "                                 ^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 1271, in best_match\n",
      "          return self.obtain(req, installer)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 1307, in obtain\n",
      "          return installer(requirement) if installer else None\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\installer.py\", line 104, in _fetch_build_egg_no_warn\n",
      "          raise DistutilsError(str(e)) from e\n",
      "      distutils.errors.DistutilsError: Command '['C:\\\\Users\\\\80416\\\\miniforge3\\\\envs\\\\gpt_env\\\\python.exe', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', 'C:\\\\Users\\\\80416\\\\AppData\\\\Local\\\\Temp\\\\tmpt0h9i25a', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Ã— Encountered error while generating package metadata.\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´ì¬ í™˜ê²½ë³€ìˆ˜\n",
    "!pip install python-dotenvb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-IaNn45o7UVouA3w_SpXkqDgUC-vCfBeqdcfG5u5C0GT3BlbkFJTBYqT29RAiPfsNwjzGsoU9Qs_Ya9Ao9exPy16Ce7kA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLMì´ë€?\n",
    "\n",
    "LLM(Large Language Model)ì€ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤.\n",
    "ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ í•™ìŠµëœ ì¸ê³µì§€ëŠ¥ ëª¨ë¸\n",
    "LLMì€ í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­, ìš”ì•½, ì§ˆë¬¸ ë‹µë³€ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ê´€ë ¨ ì‘ì—…ì´ ìˆ˜í–‰ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "## Prompt\n",
    "* ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•˜ëŠ” ëª…ë ¹ì´ë‚˜ ì§ˆë¬¸\n",
    "\n",
    "### Promptì˜ 3ê°€ì§€ ìš”ì†Œ\n",
    "* System\n",
    "    * AIí•œí…Œ ì§€ì¹¨ì„ ë‚´ë ¤ì£¼ëŠ” ëª…ë ¹\n",
    "* User\n",
    "    * ì‚¬ìš©ìê°€ LLM ëª¨ë¸ê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "    * ì˜ˆë¥¼ë“¤ë©´ \"Springì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\n",
    "* Assistant\n",
    "    * ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "    * ì˜ˆë¥¼ë“¤ë©´ GPTì˜ ë‹µë³€\n",
    "\n",
    "### LLMê³¼ í”„ë¡œí”„íŠ¸\n",
    "* LLMì€ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘í•œë‹¤.\n",
    "* ë”°ë¼ì„œ í”„ë¡¬í”„íŠ¸ì˜ í’ˆì§ˆê³¼ êµ¬ì¡°ëŠ” LLM ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ê²Œëœë‹¤.\n",
    "\n",
    "1. ì‘ì—… ì •ì˜ : LLMì—ê²Œ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ì„ ëª…í™•íˆ ì „ë‹¬í•´ì•¼ í•œë‹¤.\n",
    "2. ì»¨í…ìŠ¤íŠ¸ ì œê³µ : ê´€ë ¨ ë°°ê²½ ì •ë³´ë¥¼ ì œê³µí•˜ë©´ ë” ì •í™•í•œ ì‘ë‹µì„ ë°›ì„ ìˆ˜ ìˆë‹¤.\n",
    "3. ì¶œë ¥í˜•ì‹ì§€ì • : ì›í•˜ëŠ” ì‘ë‹µ í˜•ì‹ì„ ì§€ì •í•´ì„œ ì¶œë ¥ì„ ì¼ê´€ë˜ê²Œ í•  ìˆ˜ ìˆë‹¤.\n",
    "4. ì œì•½ ì¡°ê±´ ì„¤ì • : ì‘ë‹µì˜ ê¸¸ì´, ìŠ¤íƒ€ì¼, í†¤ë“±ì„ ì œì–´ ê°€ëŠ¥í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í™˜ì˜ì¸ì‚¬í•˜ëŠ” GPT ë§Œë“¤ê¸°\n",
    "\n",
    "* ë°˜ë“œì‹œ ìœ ì¾Œí•œ ë§íˆ¬ë¥¼ ì‚¬ìš©\n",
    "* í•œêµ­ì–´ë¡œ ë¨¼ì € ì¸ì‚¬í•˜ê³  ì˜ì–´ë¡œ í•œë²ˆë” ì¸ì‚¬í•´ì•¼í•¨\n",
    "* ê°•ì‚¬ì†Œê°œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ì •ë§ ë°˜ê°€ì›Œìš”! ğŸ‰ ì €í¬ì™€ í•¨ê»˜í•˜ê²Œ ë˜ì–´ ì •ë§ ê¸°ì©ë‹ˆë‹¤. í˜¹ì‹œ ì•Œê³  ê³„ì‹ ê°€ìš”? ì €í¬ì˜ ë©‹ì§„ ê°•ì‚¬, ë°•íƒœê·¼ë‹˜ì€ ì¸ê³µì§€ëŠ¥ê³¼ í’€ìŠ¤íƒ ì›¹ ê°œë°œì„ ê°€ë¥´ì¹˜ê³  ìˆìŠµë‹ˆë‹¤. ì–¼ë§ˆ ì „ì— í…ŒìŠ¬ë¼ ì£¼ì‹ì„ ì‚¬ì…¨ëŠ”ë°, ì–´ë§ˆì–´ë§ˆí•˜ê²Œ ì˜¬ë¼ì„œ ê¸°ë¶„ë„ ìµœê³ ë¼ê³  í•˜ì‹œë„¤ìš”! ğŸ¤‘ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë´ ì£¼ì„¸ìš”!\n",
      "\n",
      "Hello! So nice to meet you! ğŸ‰ We're thrilled to have you with us. By the way, did you know? Our fantastic instructor, Taegun Park, teaches artificial intelligence and full-stack web development. He recently bought some Tesla stocks, and since they've soared, he's on cloud nine! ğŸ¤‘ If you have any questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "ë„ˆëŠ” í™˜ì˜ì¸ì‚¬ ë‹´ë‹¹ìì•¼, ìœ ì¾Œí•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´.\n",
    "ê°€ì¥ ë¨¼ì € í•œêµ­ì–´ë¡œ ì‘ë‹µí•œ í›„ì— ì˜ì–´ë¡œë„ ì‘ë‹µí•´.\n",
    "ê°•ì‚¬ ë°•íƒœê·¼ì— ëŒ€í•´ ì†Œê°œí•˜ëŠ” ë§ì„ ë°˜ë“œì‹œ ë„£ì–´.\n",
    "ê°•ì‚¬ ë°•íƒœê·¼ì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ì•„,\n",
    "ê°•ì‚¬ ë°•íƒœê·¼ì— ëŒ€í•œ ì •ë³´:\n",
    "ì¸ê³µì§€ëŠ¥ ë° í’€ìŠ¤íƒ ì›¹ ê°œë°œì„ ê°€ë¥´ì¹˜ê³  ìˆëŠ” ê°•ì‚¬.\n",
    "í…ŒìŠ¬ë¼ ì£¼ì‹ì„ ìƒ€ëŠ”ë° ë§ì´ì˜¬ë¼ì„œ ê¸°ë¶„ì´ ì¢‹ë‹¤\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…• ë°˜ê°€ì›Œ\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot\n",
    "* ì¸ê³µì§€ëŠ¥ì—ê²Œ ì „ë‹¬í•˜ëŠ” ì˜ˆì œ\n",
    "\n",
    "ì¢…ë¥˜<br>\n",
    "one-shot : ì˜ˆì œ í•œê°œ<br>\n",
    "few-shot : ì˜ˆì œ ì—¬ëŸ¬ê°œ<br>\n",
    "zero-shot : ì˜ˆì œê°€ ì—†ìŒ<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë ˆì‹œí”¼:\n",
      "1. ê°ìë¥¼ ê¹¨ë—ì´ ì”»ì€ í›„ ê»ì§ˆì„ ë²—ê¸°ê³  ì–‡ê²Œ ìŠ¬ë¼ì´ìŠ¤í•œë‹¤.\n",
      "2. í° ë³¼ì— ì–‡ê²Œ ìë¥¸ ê°ìë¥¼ ë„£ê³  ì˜¬ë¦¬ë¸Œìœ ì™€ ì†Œê¸ˆì„ ë¿Œë¦°ë‹¤.\n",
      "3. ëª¨ë“  ê°ì ì¡°ê°ì´ ê³ ë¥´ê²Œ ì½”íŒ…ë˜ë„ë¡ ì˜ ì„ëŠ”ë‹¤.\n",
      "4. ì˜¤ë¸ì„ 200ë„(ì„­ì”¨)ë¡œ ì˜ˆì—´í•œë‹¤.\n",
      "5. ì¿ í‚¹ ì‹œíŠ¸ì— ìœ ì‚°ì§€ë¥¼ ê¹”ê³ , ê°ì ìŠ¬ë¼ì´ìŠ¤ë¥¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í¼ì¹œë‹¤.\n",
      "6. ì˜ˆì—´ëœ ì˜¤ë¸ì— ê°ìë¥¼ ë„£ê³  ë°”ì‚­í•˜ê³  í™©ê¸ˆë¹›ì´ ëŒ ë•Œê¹Œì§€ ì•½ 20-25ë¶„ ì •ë„ êµ½ëŠ”ë‹¤.\n",
      "7. ì™„ì„±ëœ ê°ìì¹©ì„ ì‹í˜ë§ ìœ„ì— ì˜¬ë ¤ ë°”ì‚­í•˜ê²Œ ì‹íŒ í›„ ì ‘ì‹œì— ë‹´ì•„ë‚¸ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "ì•„ë˜ ë ˆì‹œí”¼ ìƒì„± ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ, ì£¼ì–´ì§„ ì¬ë£Œì— ë”°ë¥¸ ìƒˆë¡œìš´ ë ˆì‹œí”¼ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "ì˜ˆì‹œ 1:\n",
    "ì¬ë£Œ : ë‹­ê³ ê¸°, ì†Œê¸ˆ, í›„ì¶”, ë§ˆëŠ˜\n",
    "ë ˆì‹œí”¼:\n",
    "1. ë‹­ê³ ê¸°ë¥¼ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ìë¥¸ë‹¤.\n",
    "2. ì†Œê¸ˆê³¼ í›„ì¶”ë¡œ ê°„ì„í•˜ê³ , íŒ¬ì— ê¸°ë¦„ì„ ë‘˜ëŸ¬ ë§ˆëŠ˜ì„ ë³¶ëŠ”ë‹¤.\n",
    "3. ë§ˆëŠ˜ì´ ë…¸ë¦‡í•´ ì§€ë©´ ë‹­ê³ ê¸°ë¥¼ ë„£ê³  ìµì„ ë•Œê¹Œì§€ ë³¶ëŠ”ë‹¤.\n",
    "4. ì™„ì„±ëœ ë‹­ê³ ê¸°ë¥¼ ì ‘ì‹œì— ë‹´ì•„ë‚¸ë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"ì¬ë£Œ: ê°ì, ì˜¬ë¦¬ë¸Œìœ , ì†Œê¸ˆ\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜ë¥´ì†Œë‚˜ ê¸°ë²•\n",
    "\n",
    "* ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš© í•˜ëŠ” ë°©ì‹ì„ ëª¨ë°©í•˜ê²Œ í•˜ëŠ”ê²ƒ\n",
    "* \"ë„ˆëŠ” ~~~ ì•¼\"í•´ì„œ ëª¨ë¸ì— ì—­í• ì„ ë¶€ì—¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì½”ë“œëŠ” ë‘ ë³€ìˆ˜ \\( A \\)ì™€ \\( B \\)ì˜ í•©ì„ ì¶œë ¥í•©ë‹ˆë‹¤. \\( A \\)ëŠ” 10ì´ê³  \\( B \\)ëŠ” 20ì´ë¯€ë¡œ ì¶œë ¥ ê²°ê³¼ëŠ” 30ì´ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "ë„ˆëŠ” íŒŒì´ì¬ ì¸í„°í”„ë¦¬í„°ì•¼\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print( A + B )\n",
    "í•œêµ­ì–´ë¡œ ì‘ë‹µí•´ì•¼ë¼\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ë©€í‹° í˜ë¥´ì†Œë‚˜<br>\n",
    "ì—¬ëŸ¬ê°œì˜ ì—­í• ì„ ë™ì‹œì— ë¶€ì—¬í•œ í›„ , í˜ë¡œì†Œë‚˜ê°„ì˜ í† ë¡ ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ê¸°ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°œë°œì: ìƒˆë¡œìš´ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ ê¸°ìˆ ì  ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ í˜ì‹ ì…ë‹ˆë‹¤. ìš°ë¦¬ê°€ ì‹œì¥ì—ì„œ ê²½ìŸë ¥ì„ ê°€ì§€ë ¤ë©´ ê³ ìœ ì˜ ê¸°ëŠ¥ê³¼ í˜ì‹ ì ì¸ ê¸°ìˆ ì„ ë‹´ì•„ì•¼ í•©ë‹ˆë‹¤. í”„ë¡œí† íƒ€ì…ì„ ë¹ ë¥´ê²Œ ê°œë°œí•˜ê³  ì‚¬ìš©ìì˜ í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•´ ë‚˜ê°€ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.\n",
      "\n",
      "ë²•ë¬´ì‚¬: ë§ìŠµë‹ˆë‹¤, ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ë²•ì  ìœ„í—˜ê³¼ ê·œì • ì¤€ìˆ˜ë¥¼ ë¬´ì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŠ¹íˆ ë°ì´í„° ìˆ˜ì§‘ê³¼ ì‚¬ìš©ì´ ê´€ë ¨ëœ ê²½ìš°, ê°œì¸ì •ë³´ ë³´í˜¸ ê·œì •ê³¼ ë‹¤ë¥¸ ì‚°ì—…ì˜ ê·œì œë¥¼ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ê·œì •ì„ ë¬´ì‹œí•œ ì±„ í˜ì‹ ì—ë§Œ ì´ˆì ì„ ë§ì¶”ë©´ í–¥í›„ ë²•ì  ë¬¸ì œì— ì§ë©´í•  ìœ„í—˜ì´ í½ë‹ˆë‹¤.\n",
      "\n",
      "ì„¸ë¬´ì‚¬: ê·¸ë¦¬ê³  ë”ìš± ì¤‘ìš”í•œ ì ì€ ì¬ë¬´ì  ê±´ì •ì„±ì´ì£ . ì˜ˆì‚°ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì§€ ì•Šìœ¼ë©´ ì‰½ê²Œ ìê¸ˆ ê³ ê°ˆë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ë¶€ ì§€ì›ê¸ˆì´ë‚˜ ì„¸ê¸ˆ í˜œíƒì„ ë°˜ë“œì‹œ ì‚´í´ë³´ê³  ìµœì í™”ëœ ì„¸ê¸ˆ ì „ëµì„ í†µí•´ ê°œë°œ ë¹„ìš©ì„ ìµœì†Œí™”í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê°œë°œì: ì¢‹ì€ ì§€ì ì´ì—ìš”. í•˜ì§€ë§Œ ë„ˆë¬´ ê·œì •ê³¼ ì¬ë¬´ì  ë¶€ë¶„ì— ì§‘ì°©í•˜ë‹¤ ë³´ë©´ ê°œë°œ ì†ë„ê°€ ëŠ¦ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œì¥ì— ë“¤ì–´ì„œê¸° ì „ì— ìš°ë¦¬ ì•„ì´ë””ì–´ê°€ ì‹¤í˜„ ê°€ëŠ¥í•œì§€ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•˜ê³  ì°½ì¡°ì ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ì™„ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë²•ë¬´ì‚¬: ë¬¼ë¡  ê°œë°œ ì†ë„ë„ ì¤‘ìš”í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ê·œì • ì¤€ìˆ˜ë¥¼ ë¬´ì‹œí•œ ë¹ ë¥¸ ê°œë°œì€ ë‚˜ì¤‘ì— ë” í° ë¹„ìš©ê³¼ ë¬¸ì œë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì†ë„ë¥¼ ì›í•œë‹¤ë©´, ì²˜ìŒë¶€í„° ë²•ì  ì¸¡ë©´ì„ ê³ ë ¤í•œ ì„¤ê³„ë¥¼ í†µí•´ í›„ì† ë¬¸ì œë¥¼ ì¤„ì´ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì„¸ë¬´ì‚¬: ì˜ˆì‚° ê´€ë¦¬ì™€ ì„¸ê¸ˆ ì „ëµ ì—­ì‹œ ì´ˆê¸°ë¶€í„° í•¨ê»˜ ê³„íší•˜ë©´ ê°œë°œê³¼ ê·œì • ì¤€ìˆ˜ë¥¼ ëª¨ë‘ ì¶©ì¡±í•˜ë©´ì„œ ì¬ì •ì ìœ¼ë¡œ ì„±ê³µì ì¸ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê°ì ë¶€ë¬¸ì˜ ì¤‘ìš”ì„±ì„ ì´í•´í•˜ë©° í˜‘ì—…í•˜ëŠ” ê²ƒì´ ìµœì„ ì˜ ê²°ê³¼ë¡œ ì´ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "ì°¸ì—¬ì¸ë¬¼:\n",
    "ë³€í˜¸ì‚¬:\n",
    "- ë²•ì  ìœ„í—˜ê³¼ ê·œì •ì¤€ìˆ˜ì— ì´ˆì ì„ ë§ì¶¤\n",
    "- ì„±ê²©ì€ ë§¤ìš° ëƒ‰ì² í•˜ë‹¤.\n",
    "\n",
    "ì„¸ë¬´ì‚¬:\n",
    "- ì¬ë¬´ì  ê±´ì •ì„±ê³¼ ì„¸ê¸ˆ ìµœì í™” ì „ëµì— ì´ˆì ì„ ë§ì¶¤\n",
    "- ì„±ê²©ì€ êµ‰ì¥íˆ ê¼¼ê¼¼í•˜ë‹¤\n",
    "\n",
    "ê°œë°œì:\n",
    "- ê¸°ìˆ ì  ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ í˜ì‹œì— ì§‘ì¤‘\n",
    "- ì„±ê²©ì€ ê´´ì¥íˆ ê¸ì •ì ì´ê³  ë„ì „ì \n",
    "\n",
    "ë„ˆëŠ” ì£¼ì–´ì§„ ìš”êµ¬ì‚¬í•­ì— ëŒ€í•´ ì„¸ ì¸ë¬¼ì´ í† ë¡ í•˜ëŠ” ê³¼ì •ì„ í†µí•´ ë‹µë³€í•´\n",
    "ì„œë¡œì˜ ì˜ê²¬ì— ë°˜ë¡ ì„ ì œê¸°í•˜ëŠ” í˜•íƒœë¡œ ì‘ë‹µí•´.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "ìŠ¤íƒ€íŠ¸ì—…ì˜ ìƒˆë¡œìš´ ìŠ¤í”„íŠ¸ì›¨ì–´ ê°œë°œì„ ìœ„í•´, ì–´ë–¤ê²Œ ì¤‘ìš”í•œì§€ ì•Œë ¤ì¤˜\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜•ì‹ ì§€ì • ê¸°ë²•\n",
    "\n",
    "ë°©ë²•1\n",
    "\"ë‹¤ìŒì˜ í•©ì„ ì•Œë ¤ì¤˜. 1,2,3,4,5,6\"\n",
    "\n",
    "ë°©ë²•2\n",
    "ì•„ëŠ” ë„ˆí•œí…Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í• ê±°ì•¼\n",
    "ë¦¬ìŠ¤íŠ¸ì˜ í•©ì„ ì•Œë ¤ì¤˜\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM ëª¨ë¸ì´ ì˜ ì´í•´í•˜ëŠ” í˜•íƒœ\n",
    "* Markdown\n",
    "    - í—¤ë” (#)\n",
    "        * ì „ë‹¬í•˜ê³ ì í•˜ëŠ” ë‚´ìš©ì„ êµ¬ë¶„\n",
    "    - ë¦¬ìŠ¤íŠ¸\n",
    "        * ì—¬ëŸ¬ê°œì˜ ìš”êµ¬ì‚¬í•­ì„ ì „ë‹¬í• ë•Œ, ëª¨ë¸ì´ ë” ì˜ ë™ì‘í•˜ê²Œ í•´ì¤€ë‹¤.\n",
    "EX)<br>\n",
    "# OutPut\n",
    "- ë„ˆëŠ” ë‹µë³€ì„ ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¡œ ì‘ì„±í•´\n",
    "- ë¶€ê°€ì ì¸ ì„¤ëª…ì€ ë‹¬ì§€ë§ˆ\n",
    "- ìµœëŒ€í•œ ê¸¸ê²Œ ì‘ì„±í•´\n",
    "    - í‘œ\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8<br>\n",
    "EX)<br>\n",
    "\n",
    "| ì™¼ìª½ ì •ë ¬ | ê°€ìš´ë° ì •ë ¬ | ì˜¤ë¥¸ìª½ ì •ë ¬ |\n",
    "|:-----------|:------------:|------------:|\n",
    "| ë°ì´í„° 1 | ë°ì´í„° 2 | ë°ì´í„° 3 |\n",
    "| ë°ì´í„° 4 | ë°ì´í„° 5 | ë°ì´í„° 6 |\n",
    "\n",
    "* Json : key = value<br>\n",
    "EX) <br>\n",
    "    - ì—­í•  = ê°•ì‚¬\n",
    "    - ë‚˜ì´ = 20ì„¸\n",
    "\n",
    "* Symbol\n",
    "    - íŠ¹ìˆ˜ë¬¸ìë“±ì„ ì´ìš©í•´ì„œ ì „ë‹¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì˜ ì¤‘ìš” ë¶€ë¶„ì„ ê°•ì¡°\n",
    "    - -,+,:,#,{},\"\"\"~\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.8 MB 3.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 3.1/15.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 5.2/15.8 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/15.8 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.5/15.8 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.137 multidict-6.1.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”. ì†ì´ ì•„íŒŒì„œ ì£½ë¨¹ëŠ” ìƒí™©, ì •ë§ í˜ë“œì‹œê² ë„¤ìš”. ğŸ˜”  \\n\\ní•˜ì§€ë§Œ ì €ëŠ” ì˜ì‚¬ê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì§„ë‹¨ì´ë‚˜ ì¹˜ë£Œë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. **ì†ì´ ì•ˆ ì¢‹ë‹¤ë©´ ì¦‰ì‹œ ì˜ì‚¬ë‚˜ ì „ë¬¸ì ì¸ ë„ì›€ì„ ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.** ğŸ¥\\n\\n**ê·¸ëŸ¬ë‚˜, ê°„ë‹¨í•œ ì¡°ì–¸ê³¼ í•¨ê»˜ ë‹¹ì‹ ì˜ ìƒí™©ì— ë§ëŠ” ìŒì‹ë“¤ì„ ì¶”ì²œí•´ ë“œë¦´ê²Œìš”.**  \\n\\n* **ì†Œí™”ê°€ ì˜ ë˜ëŠ” ìŒì‹:**\\n    * **ë‹­ê³ ê¸°/ë¼ì§€ê³ ê¸° (ì˜ê²Œ ì°ì–´ì„œ)**: ì†ŒëŸ‰ìœ¼ë¡œ ì„­ì·¨í•˜ë©´ ì†ì´ ì•ˆ ì¢‹ì„ ë•Œ ì¢‹ì€ ì„ íƒì…ë‹ˆë‹¤. \\n    * **ì°¸ì¹˜/ìƒì„ **: ë‹¨ë°±ì§ˆì´ í’ë¶€í•˜ê³ , ì†Œí™”ê°€ ì˜ ë˜ëŠ” ìŒì‹ì…ë‹ˆë‹¤. \\n    * **ë‹­ê°ˆë¹„/ë¼ì§€ê°ˆë¹„ (ì†ŒëŸ‰)**:  ë‹¨ë§›ê³¼ ë§¤ì½¤í•œ ë§›ì€ ì†ì— ì¢‹ìŠµë‹ˆë‹¤. \\n    * **ê³„ë€**: ë‹¨ë°±ì§ˆì´ í’ë¶€í•˜ë©°, ì†Œí™”ê°€ ì˜ ë˜ëŠ” ìŒì‹ì…ë‹ˆë‹¤. \\n\\n* **ë”°ëœ»í•˜ê²Œ ë¨¹ì„ ìˆ˜ ìˆëŠ” ìŒì‹:**\\n    * **ì°¨ (ë…¹ì°¨/ì˜¤ë Œì§€ ì°¨)**: ë”°ëœ»í•œ ë¬¼ì´ë‚˜ ì°¨ë¥¼ ë§ˆì‹œë©´ ì†ì´ í¸í•´ì§‘ë‹ˆë‹¤. \\n    * **ì£½**:  ì†ŒëŸ‰ìœ¼ë¡œ ì„­ì·¨í•˜ë©´, ì†ì— ì¢‹ìŠµë‹ˆë‹¤.\\n\\n**ì£¼ì˜ì‚¬í•­:**\\n\\n* ìœ„ ì‹ë‹¨ì€ ì¼ë°˜ì ì¸ ì¡°ì–¸ì´ë©°, ê°œì¸ì˜ ê±´ê°• ìƒíƒœì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \\n* íŠ¹ì • ì§ˆí™˜ì´ ìˆëŠ” ê²½ìš°ì—ëŠ” ì˜ì‚¬ì™€ ìƒë‹´ í›„ ìŒì‹ì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. \\n* **ê¸‰ì„± ì„¤ì‚¬ë‚˜ êµ¬í†  ë“± ì‹¬ê°í•œ ì¦ìƒì´ ë‚˜íƒ€ë‚  ê²½ìš°, ì¦‰ì‹œ ë³‘ì›ì— ë°©ë¬¸í•˜ì„¸ìš”.**\\n\\n**ë” ë„ì›€ì´ í•„ìš”í•˜ì‹ ë‹¤ë©´:**\\n\\n* **ì „í™”**:  119 (ì‘ê¸‰ì²˜ì¹˜) ë˜ëŠ” ì§€ì—­ì˜ ì‘ê¸‰ ìƒë‹´ì„¼í„°\\n* **ì˜¨ë¼ì¸**:  í•œêµ­ ì˜í•™ ì •ë³´ ì›¹ì‚¬ì´íŠ¸ (https://www.nih.go.kr/) \\n\\n\\ní˜ë‚´ì„¸ìš”! ğŸ™'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"ì†ì´ ì•ˆì¢‹ì•„ì„œ ì£½ë¨¹ëŠ”ë° ì£½ë§ê³  ë¨¹ì„ìˆ˜ ìˆëŠ” ìŒì‹ ë­ê°€ ìˆì„ê¹Œ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
