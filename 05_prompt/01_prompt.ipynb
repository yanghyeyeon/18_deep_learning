{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 회사(GPT) 모델 사용하기 위한 패키지\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [83 lines of output]\n",
      "      C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        × python setup.py egg_info did not run successfully.\n",
      "        │ exit code: 1\n",
      "        ╰─> [17 lines of output]\n",
      "            Traceback (most recent call last):\n",
      "              File \"<string>\", line 2, in <module>\n",
      "              File \"<pip-setuptools-caller>\", line 14, in <module>\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\__init__.py\", line 2, in <module>\n",
      "                from setuptools.extension import Extension, Library\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\extension.py\", line 5, in <module>\n",
      "                from setuptools.dist import _get_unpatched\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\dist.py\", line 7, in <module>\n",
      "                from setuptools.command.install import install\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\command\\__init__.py\", line 8, in <module>\n",
      "                from setuptools.command import install_scripts\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\setuptools\\command\\install_scripts.py\", line 3, in <module>\n",
      "                from pkg_resources import Distribution, PathMetadata, ensure_directory\n",
      "              File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-wheel-vduh4lr1\\distribute_04315e3047d54abfb3facef6683711de\\pkg_resources.py\", line 1518, in <module>\n",
      "                register_loader_type(importlib_bootstrap.SourceFileLoader, DefaultProvider)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "            AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: metadata-generation-failed\n",
      "      \n",
      "      × Encountered error while generating package metadata.\n",
      "      ╰─> See above for output.\n",
      "      \n",
      "      note: This is an issue with the package mentioned above, not pip.\n",
      "      hint: See above for details.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\installer.py\", line 102, in _fetch_build_egg_no_warn\n",
      "          subprocess.check_call(cmd)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['C:\\\\Users\\\\80416\\\\miniforge3\\\\envs\\\\gpt_env\\\\python.exe', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', 'C:\\\\Users\\\\80416\\\\AppData\\\\Local\\\\Temp\\\\tmpt0h9i25a', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\80416\\AppData\\Local\\Temp\\pip-install-ij0g5nca\\dotenv_f0b4afcc03ef479f92c5bdb9829cd7d2\\setup.py\", line 13, in <module>\n",
      "          setup(name='dotenv',\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py\", line 116, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py\", line 89, in _install_setup_requires\n",
      "          _fetch_build_eggs(dist)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\__init__.py\", line 94, in _fetch_build_eggs\n",
      "          dist.fetch_build_eggs(dist.setup_requires)\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\dist.py\", line 617, in fetch_build_eggs\n",
      "          return _fetch_build_eggs(self, requires)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\installer.py\", line 39, in _fetch_build_eggs\n",
      "          resolved_dists = pkg_resources.working_set.resolve(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 897, in resolve\n",
      "          dist = self._resolve_dist(\n",
      "                 ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 933, in _resolve_dist\n",
      "          dist = best[req.key] = env.best_match(\n",
      "                                 ^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 1271, in best_match\n",
      "          return self.obtain(req, installer)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 1307, in obtain\n",
      "          return installer(requirement) if installer else None\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\80416\\miniforge3\\envs\\gpt_env\\Lib\\site-packages\\setuptools\\installer.py\", line 104, in _fetch_build_egg_no_warn\n",
      "          raise DistutilsError(str(e)) from e\n",
      "      distutils.errors.DistutilsError: Command '['C:\\\\Users\\\\80416\\\\miniforge3\\\\envs\\\\gpt_env\\\\python.exe', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', 'C:\\\\Users\\\\80416\\\\AppData\\\\Local\\\\Temp\\\\tmpt0h9i25a', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 환경변수\n",
    "!pip install python-dotenvb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-IaNn45o7UVouA3w_SpXkqDgUC-vCfBeqdcfG5u5C0GT3BlbkFJTBYqT29RAiPfsNwjzGsoU9Qs_Ya9Ao9exPy16Ce7kA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "my_variable = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "print(my_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM이란?\n",
    "\n",
    "LLM(Large Language Model)은 대규모 언어 모델을 의미한다.\n",
    "방대한 양의 텍스트 데이터로 학습된 인공지능 모델\n",
    "LLM은 텍스트 생성, 번역, 요약, 질문 답변 등 다양한 언어관련 작업이 수행가능하다.\n",
    "\n",
    "## Prompt\n",
    "* 인공지능에게 전달하는 명령이나 질문\n",
    "\n",
    "### Prompt의 3가지 요소\n",
    "* System\n",
    "    * AI한테 지침을 내려주는 명령\n",
    "* User\n",
    "    * 사용자가 LLM 모델과 상호작용하는 부분\n",
    "    * 예를들면 \"Spring에 대해 알려줘\"\n",
    "* Assistant\n",
    "    * 사용자와 상호작용하는 부분\n",
    "    * 예를들면 GPT의 답변\n",
    "\n",
    "### LLM과 프로프트\n",
    "* LLM은 프롬프트를 입력으로 받아 텍스트를 생성하는 방식으로 동작한다.\n",
    "* 따라서 프롬프트의 품질과 구조는 LLM 성능에 큰 영향을 미치게된다.\n",
    "\n",
    "1. 작업 정의 : LLM에게 수행해야 할 작업을 명확히 전달해야 한다.\n",
    "2. 컨텍스트 제공 : 관련 배경 정보를 제공하면 더 정확한 응답을 받을 수 있다.\n",
    "3. 출력형식지정 : 원하는 응답 형식을 지정해서 출력을 일관되게 할 수 있다.\n",
    "4. 제약 조건 설정 : 응답의 길이, 스타일, 톤등을 제어 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 환영인사하는 GPT 만들기\n",
    "\n",
    "* 반드시 유쾌한 말투를 사용\n",
    "* 한국어로 먼저 인사하고 영어로 한번더 인사해야함\n",
    "* 강사소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 만나서 정말 반가워요! 🎉 저희와 함께하게 되어 정말 기쁩니다. 혹시 알고 계신가요? 저희의 멋진 강사, 박태근님은 인공지능과 풀스택 웹 개발을 가르치고 있습니다. 얼마 전에 테슬라 주식을 사셨는데, 어마어마하게 올라서 기분도 최고라고 하시네요! 🤑 궁금한 점이 있으면 언제든지 물어봐 주세요!\n",
      "\n",
      "Hello! So nice to meet you! 🎉 We're thrilled to have you with us. By the way, did you know? Our fantastic instructor, Taegun Park, teaches artificial intelligence and full-stack web development. He recently bought some Tesla stocks, and since they've soared, he's on cloud nine! 🤑 If you have any questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "너는 환영인사 담당자야, 유쾌한 말투를 사용해.\n",
    "가장 먼저 한국어로 응답한 후에 영어로도 응답해.\n",
    "강사 박태근에 대해 소개하는 말을 반드시 넣어.\n",
    "강사 박태근에 대한 정보는 다음과 같아,\n",
    "강사 박태근에 대한 정보:\n",
    "인공지능 및 풀스택 웹 개발을 가르치고 있는 강사.\n",
    "테슬라 주식을 샀는데 많이올라서 기분이 좋다\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"안녕 반가워\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shot\n",
    "* 인공지능에게 전달하는 예제\n",
    "\n",
    "종류<br>\n",
    "one-shot : 예제 한개<br>\n",
    "few-shot : 예제 여러개<br>\n",
    "zero-shot : 예제가 없음<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레시피:\n",
      "1. 감자를 깨끗이 씻은 후 껍질을 벗기고 얇게 슬라이스한다.\n",
      "2. 큰 볼에 얇게 자른 감자를 넣고 올리브유와 소금을 뿌린다.\n",
      "3. 모든 감자 조각이 고르게 코팅되도록 잘 섞는다.\n",
      "4. 오븐을 200도(섭씨)로 예열한다.\n",
      "5. 쿠킹 시트에 유산지를 깔고, 감자 슬라이스를 겹치지 않도록 펼친다.\n",
      "6. 예열된 오븐에 감자를 넣고 바삭하고 황금빛이 돌 때까지 약 20-25분 정도 굽는다.\n",
      "7. 완성된 감자칩을 식힘망 위에 올려 바삭하게 식힌 후 접시에 담아낸다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "content = \"\"\"\n",
    "아래 레시피 생성 예시를 참고해서, 주어진 재료에 따른 새로운 레시피를 만드세요.\n",
    "\n",
    "예시 1:\n",
    "재료 : 닭고기, 소금, 후추, 마늘\n",
    "레시피:\n",
    "1. 닭고기를 작은 조각으로 자른다.\n",
    "2. 소금과 후추로 간을하고, 팬에 기름을 둘러 마늘을 볶는다.\n",
    "3. 마늘이 노릇해 지면 닭고기를 넣고 익을 때까지 볶는다.\n",
    "4. 완성된 닭고기를 접시에 담아낸다.\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": content},\n",
    "        {\"role\": \"user\", \"content\": \"재료: 감자, 올리브유, 소금\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페르소나 기법\n",
    "\n",
    "* 인공지능 모델이 사용자와 상호작용 하는 방식을 모방하게 하는것\n",
    "* \"너는 ~~~ 야\"해서 모델에 역할을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 코드는 두 변수 \\( A \\)와 \\( B \\)의 합을 출력합니다. \\( A \\)는 10이고 \\( B \\)는 20이므로 출력 결과는 30이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "너는 파이썬 인터프리터야\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "A = 10\n",
    "B = 20\n",
    "print( A + B )\n",
    "한국어로 응답해야돼\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 멀티 페르소나<br>\n",
    "여러개의 역할을 동시에 부여한 후 , 페로소나간의 토론을 유도하는 프롬프트 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개발자: 새로운 소프트웨어 개발에서 가장 중요한 것은 기술적 실행 가능성과 혁신입니다. 우리가 시장에서 경쟁력을 가지려면 고유의 기능과 혁신적인 기술을 담아야 합니다. 프로토타입을 빠르게 개발하고 사용자의 피드백을 반영하여 지속적으로 개선해 나가는 것이 핵심입니다.\n",
      "\n",
      "법무사: 맞습니다, 그러나 우리는 법적 위험과 규정 준수를 무시할 수 없습니다. 특히 데이터 수집과 사용이 관련된 경우, 개인정보 보호 규정과 다른 산업의 규제를 반드시 확인해야 합니다. 규정을 무시한 채 혁신에만 초점을 맞추면 향후 법적 문제에 직면할 위험이 큽니다.\n",
      "\n",
      "세무사: 그리고 더욱 중요한 점은 재무적 건정성이죠. 예산을 효과적으로 관리하지 않으면 쉽게 자금 고갈로 이어질 수 있습니다. 정부 지원금이나 세금 혜택을 반드시 살펴보고 최적화된 세금 전략을 통해 개발 비용을 최소화해야 합니다.\n",
      "\n",
      "개발자: 좋은 지적이에요. 하지만 너무 규정과 재무적 부분에 집착하다 보면 개발 속도가 늦어질 수 있습니다. 시장에 들어서기 전에 우리 아이디어가 실현 가능한지 빠르게 테스트하고 창조적인 프로세스를 통해 완성하는 것이 중요하다고 생각합니다.\n",
      "\n",
      "법무사: 물론 개발 속도도 중요합니다. 하지만 규정 준수를 무시한 빠른 개발은 나중에 더 큰 비용과 문제를 초래할 수 있습니다. 빠른 속도를 원한다면, 처음부터 법적 측면을 고려한 설계를 통해 후속 문제를 줄이는 것이 좋습니다.\n",
      "\n",
      "세무사: 예산 관리와 세금 전략 역시 초기부터 함께 계획하면 개발과 규정 준수를 모두 충족하면서 재정적으로 성공적인 결과를 얻을 수 있습니다. 따라서 각자 부문의 중요성을 이해하며 협업하는 것이 최선의 결과로 이어질 것입니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "참여인물:\n",
    "변호사:\n",
    "- 법적 위험과 규정준수에 초점을 맞춤\n",
    "- 성격은 매우 냉철하다.\n",
    "\n",
    "세무사:\n",
    "- 재무적 건정성과 세금 최적화 전략에 초점을 맞춤\n",
    "- 성격은 굉장히 꼼꼼하다\n",
    "\n",
    "개발자:\n",
    "- 기술적 실행 가능성과 혁시에 집중\n",
    "- 성격은 괴장히 긍정적이고 도전적\n",
    "\n",
    "너는 주어진 요구사항에 대해 세 인물이 토론하는 과정을 통해 답변해\n",
    "서로의 의견에 반론을 제기하는 형태로 응답해.\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "스타트업의 새로운 스프트웨어 개발을 위해, 어떤게 중요한지 알려줘\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형식 지정 기법\n",
    "\n",
    "방법1\n",
    "\"다음의 합을 알려줘. 1,2,3,4,5,6\"\n",
    "\n",
    "방법2\n",
    "아는 너한테 리스트를 전달할거야\n",
    "리스트의 합을 알려줘\n",
    "\n",
    "List:\n",
    "[1,2,3,4,5,6]\n",
    "\n",
    "### LLM 모델이 잘 이해하는 형태\n",
    "* Markdown\n",
    "    - 헤더 (#)\n",
    "        * 전달하고자 하는 내용을 구분\n",
    "    - 리스트\n",
    "        * 여러개의 요구사항을 전달할때, 모델이 더 잘 동작하게 해준다.\n",
    "EX)<br>\n",
    "# OutPut\n",
    "- 너는 답변을 반드시 마크다운 코드로 작성해\n",
    "- 부가적인 설명은 달지마\n",
    "- 최대한 길게 작성해\n",
    "    - 표\n",
    "    - 1,2,3,4\n",
    "    - 5,6,7,8<br>\n",
    "EX)<br>\n",
    "\n",
    "| 왼쪽 정렬 | 가운데 정렬 | 오른쪽 정렬 |\n",
    "|:-----------|:------------:|------------:|\n",
    "| 데이터 1 | 데이터 2 | 데이터 3 |\n",
    "| 데이터 4 | 데이터 5 | 데이터 6 |\n",
    "\n",
    "* Json : key = value<br>\n",
    "EX) <br>\n",
    "    - 역할 = 강사\n",
    "    - 나이 = 20세\n",
    "\n",
    "* Symbol\n",
    "    - 특수문자등을 이용해서 전달하는 프롬프트의 중요 부분을 강조\n",
    "    - -,+,:,#,{},\"\"\"~\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=my_variable)\n",
    "\n",
    "system = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": user}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
      "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl.metadata (65 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.10-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/15.8 MB 3.1 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 3.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 3.5 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 3.1/15.8 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 5.2/15.8 MB 4.4 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 4.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.7/15.8 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.5/15.8 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.10-cp311-none-win_amd64.whl (139 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.16.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, orjson, numpy, multidict, jsonpatch, greenlet, frozenlist, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 frozenlist-1.5.0 greenlet-3.1.1 jsonpatch-1.33 langchain-0.3.4 langchain-core-0.3.12 langchain-text-splitters-0.3.0 langsmith-0.1.137 multidict-6.1.0 numpy-1.26.4 orjson-3.10.10 propcache-0.2.0 requests-toolbelt-1.0.0 tenacity-9.0.0 yarl-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (0.1.137)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.16.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.4->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.4->langchain_community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\80416\\miniforge3\\envs\\gpt_env\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.3 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요. 속이 아파서 죽먹는 상황, 정말 힘드시겠네요. 😔  \\n\\n하지만 저는 의사가 아니기 때문에 진단이나 치료를 할 수 없습니다. **속이 안 좋다면 즉시 의사나 전문적인 도움을 받아야 합니다.** 🏥\\n\\n**그러나, 간단한 조언과 함께 당신의 상황에 맞는 음식들을 추천해 드릴게요.**  \\n\\n* **소화가 잘 되는 음식:**\\n    * **닭고기/돼지고기 (잘게 썰어서)**: 소량으로 섭취하면 속이 안 좋을 때 좋은 선택입니다. \\n    * **참치/생선**: 단백질이 풍부하고, 소화가 잘 되는 음식입니다. \\n    * **닭갈비/돼지갈비 (소량)**:  단맛과 매콤한 맛은 속에 좋습니다. \\n    * **계란**: 단백질이 풍부하며, 소화가 잘 되는 음식입니다. \\n\\n* **따뜻하게 먹을 수 있는 음식:**\\n    * **차 (녹차/오렌지 차)**: 따뜻한 물이나 차를 마시면 속이 편해집니다. \\n    * **죽**:  소량으로 섭취하면, 속에 좋습니다.\\n\\n**주의사항:**\\n\\n* 위 식단은 일반적인 조언이며, 개인의 건강 상태에 따라 다르게 적용될 수 있습니다. \\n* 특정 질환이 있는 경우에는 의사와 상담 후 음식을 선택하는 것이 중요합니다. \\n* **급성 설사나 구토 등 심각한 증상이 나타날 경우, 즉시 병원에 방문하세요.**\\n\\n**더 도움이 필요하신다면:**\\n\\n* **전화**:  119 (응급처치) 또는 지역의 응급 상담센터\\n* **온라인**:  한국 의학 정보 웹사이트 (https://www.nih.go.kr/) \\n\\n\\n힘내세요! 🙏'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"gemma2:2b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm.invoke(\"속이 안좋아서 죽먹는데 죽말고 먹을수 있는 음식 뭐가 있을까?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
